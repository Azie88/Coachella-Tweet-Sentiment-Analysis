{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma48R9gJTf0K"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Azie88/Coachella-Tweet-Sentiment-Analysis/blob/main/Sentiment_Analysis_Coachella.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hVz1UvpT6nV"
      },
      "source": [
        "# Sentiment Analysis Using Colab and Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXfft8TKT6na"
      },
      "source": [
        "What's Deep Learning? - Just machine learning based on artificial neural networks in which multiple layers of processing are used to extract progressively higher level features from data.\n",
        "\n",
        "Unstructured Data - Think video, audio, images, and big chunks of text. It's anything that doesn't neatly fit into a database or a spreadsheet in neat rows and columns. It's the messy kind of data that humans generate as easily as we breathe.\n",
        "\n",
        "In this project, we will fine-tune pre-trained Deep Learning models from HuggingFace on a new dataset to adapt the models to the task that we want to solve, then create an app to use the models and deploy the app on the HuggingFace platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtOheklvUGWA"
      },
      "source": [
        "### Install Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oco0avIgUpE3"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J52r5-SLUScL"
      },
      "source": [
        "### Import Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmFBqg9YUTPS"
      },
      "outputs": [],
      "source": [
        "#System and data handling\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Data Analysis & Preparation\n",
        "from evaluate import load\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "\n",
        "#Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "#Transformers\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, TFAutoModelForSequenceClassification\n",
        "\n",
        "#Scores\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "#Huggingface\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4E5M3fpYrVH"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0kcFPH_YvOO"
      },
      "outputs": [],
      "source": [
        "# Set a fixed random seed for PyTorch on CPU\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Control the seed for individual GPU operations (optional)\n",
        "if torch.cuda.is_available:\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.cuda.manual_seed_all(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oFJy-I4Y3qt"
      },
      "outputs": [],
      "source": [
        "# Connect to your google drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_4WTHvgY9IZ"
      },
      "outputs": [],
      "source": [
        "# Set CUDA_LAUNCH_BLOCKING for debugging\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrwE2UYhBO1I"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nDHMDFpBPhh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Sentiment Analysis NLP/Dataset/Coachella-2015-2-DFE.csv', encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2oFzsWqBck1"
      },
      "outputs": [],
      "source": [
        "#look at first 10 rows in train data\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVPYsuV9Cvoa"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['coachella_yn', 'name', 'retweet_count', 'tweet_coord', 'tweet_id', 'user_timezone','tweet_location', 'tweet_created'])\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhFnLYnrD3I8"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL24O4aID6wG"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjJBgV5cD-3B"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0ybs8fXEcrd"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPB_OMzHWRHK"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'coachella_sentiment': 'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDa67udiFYcS"
      },
      "outputs": [],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL9ikdM2Fjzb"
      },
      "outputs": [],
      "source": [
        "df.text.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XefSl9-fFvfu"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "1. Remove rows with *'can't tell'* sentiment values.\n",
        "2. Clean *safe-text* column of Twitter Handles, HTML characters, URLs and other non alphabetic characters. Text is inconsistent and may affect model performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz2WIOpTGa6p"
      },
      "outputs": [],
      "source": [
        "df = df[df['label'] != 'cant tell']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o8sCP3MIJ5c"
      },
      "outputs": [],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4XkToO6J1Dn"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Convert text to lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove tweet mentions\n",
        "    text = re.sub(r'<user>', '', text)\n",
        "    text = re.sub(r'<url>', '', text)\n",
        "\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Replace all whitespace characters with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agd8M9baKlWk"
      },
      "outputs": [],
      "source": [
        "# Apply the clean_text function to the 'safe_text' column\n",
        "df['text'] = df.text.apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoaJHEboKsfH"
      },
      "outputs": [],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtwFzEkNMrwd"
      },
      "outputs": [],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDpJT9UfN0GV"
      },
      "outputs": [],
      "source": [
        "sentiment_mapping = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "\n",
        "# Map the sentiment labels to numerical values\n",
        "df['label'] = df['label'].map(sentiment_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUU_aqXSN6KX"
      },
      "outputs": [],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqQxxF1DNQmG"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imF3izO_NRDu"
      },
      "outputs": [],
      "source": [
        "# pie chart wth 'labels' column\n",
        "plt.figure(figsize=(6,6))\n",
        "explode=0.1,0\n",
        "df.label.value_counts().plot.pie(autopct='%1.2f%%',labels=['Positive','Neutral','Negative'])\n",
        "plt.legend(bbox_to_anchor=(1.5,1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpivfwHGOG6_"
      },
      "outputs": [],
      "source": [
        "# Word Cloud\n",
        "all_data = df['text'].to_string()\n",
        "wordcloud = WordCloud().generate(all_data)\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(wordcloud,interpolation='bilinear')\n",
        "plt.title('Most Common Words')\n",
        "plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaIvO40zOWkf"
      },
      "outputs": [],
      "source": [
        "# Word Count\n",
        "temp_list = df['text'].apply(lambda x:str(x).split())\n",
        "top = Counter([item for sublist in temp_list for item in sublist])\n",
        "temp = pd.DataFrame(top.most_common(20))\n",
        "temp.columns = ['Common_words','count']\n",
        "temp.style.background_gradient(cmap='Blues')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l04fg4lQPyd"
      },
      "outputs": [],
      "source": [
        "text_lengths = df['text'].str.split().str.len()\n",
        "text_lengths.value_counts().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAncVsx4QmaP"
      },
      "outputs": [],
      "source": [
        "# Calculate the average\n",
        "average_length = np.mean(text_lengths)\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Using plt.hist to create a histogram with Matplotlib\n",
        "ax.hist(text_lengths, bins=20, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
        "\n",
        "# Add average line\n",
        "ax.axvline(average_length, color='red', linestyle='dashed', linewidth=2, label=f'Average: {average_length:.2f}')\n",
        "\n",
        "ax.set_title('Histogram of Tweet Lengths')\n",
        "ax.set_xlabel('Tweet Length')\n",
        "ax.set_ylabel('Count')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGevQfeQx_x"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POB_ZWTIQyjD"
      },
      "outputs": [],
      "source": [
        "# Split the train data => {train, eval}\n",
        "train, eval = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln-YZNY4RAbr"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqmKKD89RZjW"
      },
      "outputs": [],
      "source": [
        "eval.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZX__VJYRgdt"
      },
      "outputs": [],
      "source": [
        "print(f\"new dataframe shapes: train is {train.shape}, eval is {eval.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g650UxoRRkfC"
      },
      "outputs": [],
      "source": [
        "# Save split subsets\n",
        "train.to_csv(\"/content/drive/MyDrive/Sentiment Analysis NLP/Dataset/train_subset.csv\", index=False)\n",
        "eval.to_csv(\"/content/drive/MyDrive/Sentiment Analysis NLP/Dataset/eval_subset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6_CiMFDR_3O"
      },
      "outputs": [],
      "source": [
        "# Load split subsets\n",
        "\n",
        "dataset = load_dataset('csv',\n",
        "                        data_files={'train': '/content/drive/MyDrive/Sentiment Analysis NLP/Dataset/train_subset.csv',\n",
        "                        'eval': '/content/drive/MyDrive/Sentiment Analysis NLP/Dataset/eval_subset.csv'}, encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNIHOcLzSjx6"
      },
      "source": [
        "## Model Fine Tuning and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LvzE6coTf5v"
      },
      "outputs": [],
      "source": [
        "#login to huggingface with access token\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJSHTOkQSkhR"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "nlp = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skleONJ1VIx6"
      },
      "outputs": [],
      "source": [
        "def transform_labels(label):\n",
        "\n",
        "    label = label['label']\n",
        "    num = 0\n",
        "    if label == -1: #'Negative'\n",
        "        num = 0\n",
        "    elif label == 0: #'Neutral'\n",
        "        num = 1\n",
        "    elif label == 1: #'Positive'\n",
        "        num = 2\n",
        "\n",
        "    return {'labels': num}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o03xHUINUMfB"
      },
      "outputs": [],
      "source": [
        "# Function to tokenize data\n",
        "\n",
        "def tokenize_data(example):\n",
        "    return tokenizer(example['text'], padding=True, max_length = 'max_length')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oovzsl8jUlqG"
      },
      "outputs": [],
      "source": [
        "# Change the tweets to tokens that the model can use\n",
        "dataset = dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "# Transform\tlabels and remove the useless columns\n",
        "remove_columns = ['label', 'text']\n",
        "dataset = dataset.map(transform_labels, remove_columns=remove_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_meiLHYVwws"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZDaXG2vYX5a"
      },
      "source": [
        "#### Balancing Target Classes\n",
        "\n",
        "Since our target has imbalanced class weights (positive, neutral and negative dont have an equal number of samples), we want to give more weight to underrepresented classes and give less weight to classes with more samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewl8fmQVYYjU"
      },
      "outputs": [],
      "source": [
        "# Define the labels\n",
        "labels = dataset['train']['labels']\n",
        "\n",
        "# Apply the compute class weight function to calculate the class weight\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znVYAH6UYkVP"
      },
      "source": [
        "The `balanced` option in compute_class_weight will calculate weights such that the classes are balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D5T3mdFYk0q"
      },
      "outputs": [],
      "source": [
        "# Preview class weights\n",
        "class_weights, np.unique(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1cybVoYYtU6"
      },
      "outputs": [],
      "source": [
        "# Define an instance of the pre-trained model with the number of labels\n",
        "model = AutoModelForSequenceClassification.from_pretrained(nlp, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHbY2eXmaPNh"
      },
      "outputs": [],
      "source": [
        "# Configure the training parameters\n",
        "\n",
        "training_args = TrainingArguments(\"Coachella_sentiment_analysis_roberta\",\n",
        "    num_train_epochs=5, # the number of times the model will repeat the training loop over the dataset\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLv_XcUxdINX"
      },
      "outputs": [],
      "source": [
        "# evaluation metrics\n",
        "metric = load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZL6wMEpdjgy"
      },
      "outputs": [],
      "source": [
        "# Instantiate the training and validation sets with random state of 10\n",
        "train_dataset = dataset['train'].shuffle(seed=10)\n",
        "eval_dataset = dataset['eval'].shuffle(seed=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkcTYp4ednpu"
      },
      "outputs": [],
      "source": [
        "# Convert train data to PyTorch tensors to speed up training and add padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,padding=True, max_length='max_length', return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2JTFnW3dtDP"
      },
      "outputs": [],
      "source": [
        "# Define Custom Trainer | Modify loss function and assign computed weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Ensure logits and labels have compatible shapes\n",
        "        assert logits.shape[1] == self.model.config.num_labels, f\"Logits shape {logits.shape} does not match number of labels {self.model.config.num_labels}\"\n",
        "        assert labels.max() < self.model.config.num_labels, f\"Labels contain values outside the valid range: {labels}\"\n",
        "\n",
        "        # Ensure labels are of integer type\n",
        "        assert labels.dtype == torch.long, f\"Labels must be of type torch.long, but got {labels.dtype}\"\n",
        "\n",
        "        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(model.device)\n",
        "\n",
        "        # Compute custom loss\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0u4v8Xld07j"
      },
      "outputs": [],
      "source": [
        "# Instantiate the trainer for training\n",
        "c_trainer = CustomTrainer(\n",
        "                  model=model,\n",
        "                  args=training_args,\n",
        "                  train_dataset=train_dataset,\n",
        "                  eval_dataset=eval_dataset,\n",
        "                  tokenizer = tokenizer,\n",
        "                  compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In3ct-jld9nK"
      },
      "outputs": [],
      "source": [
        "# Launch the learning process: training\n",
        "c_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_YbLR5NeAQy"
      },
      "outputs": [],
      "source": [
        "# Launch the final evaluation\n",
        "c_trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVmQkSGFsxNk"
      },
      "outputs": [],
      "source": [
        "# Push model and tokenizer to HF Hub\n",
        "model.push_to_hub(\"Azie88/Coachella_sentiment_analysis_roberta\")\n",
        "tokenizer.push_to_hub(\"Azie88/Coachella_sentiment_analysis_roberta\")\n",
        "dataset.push_to_hub(\"Azie88/Coachella_sentiment_analysis_roberta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khQRfj9RtGfE"
      },
      "source": [
        "This notebook is inspired by an article: [Fine-Tuning Bert for Tweets Classification ft. Hugging Face](https://medium.com/mlearning-ai/fine-tuning-bert-for-tweets-classification-ft-hugging-face-8afebadd5dbf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsiRxogqtKuK"
      },
      "source": [
        "## Inference\n",
        "Let's test out our model with with some sample text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAuc0l1ytHD0"
      },
      "outputs": [],
      "source": [
        "model_path = f\"Azie88/Coachella_sentiment_analysis_roberta\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "config = AutoConfig.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gq9pz7juKXv"
      },
      "outputs": [],
      "source": [
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rht1gUK2uMdC"
      },
      "outputs": [],
      "source": [
        "# Input preprocessing\n",
        "text = \"that saturday lineup is fire, except for Jack White\"\n",
        "text = preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oJOTtUuuXIv"
      },
      "outputs": [],
      "source": [
        "# PyTorch-based models\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IJHRm8ruZfE"
      },
      "outputs": [],
      "source": [
        "print(\"Scores:\", scores)\n",
        "print(\"id2label Dictionary:\", config.id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJaOfgQ3uc-6"
      },
      "outputs": [],
      "source": [
        "config.id2label = {0: 'NEGATIVE', 1: 'NEUTRAL', 2: 'POSITIVE'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imes3klbuftx"
      },
      "outputs": [],
      "source": [
        "# Print labels and scores\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = config.id2label[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}